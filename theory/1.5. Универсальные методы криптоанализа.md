### 1.5. Универсальные методы криптоанализа

         За последнее десятилетие увеличилось число новых криптографических исследований и методов анализа 
         криптостойкости алгоритмов шифрования. Каждый год разрабатываются все более и более совершенные методы 
         вскрытия сложных шифров.
         Несмотря на такое многообразие методов криптоанализа, особый интерес для криптоаналитиков представляют так 
         называемые «универсальные методы криптоанализа», которые служат для раскрытия максимального числа шифров. 
         Более того, такие способы криптографического исследования шифра обладают замечательным свойством – они 
         применимы ко многим видам шифров.
         Итак, ко множеству универсальных методов криптоанализа можно отнести:

   #### 1.5.1. Метод полного перебора
   
         Данный метод состоит из полного перебора всех ключей со скоростью около тысячи ключей в секунду. В начале 
         исследования у криптоаналитика есть только одна из нескольких пар (x,y), при этом для каждой пары (xi,yi) 
         существует единственный ключ k, который соответствует следующему выражению: Ek(x)=y. Получается, что полный 
         перебор всех ключей будет составлять |K| операций, где |K| - это число элементов во множестве K, из которого 
         мы берем ключи для проверки (k€K).
         Чтобы произвести ускоренный поиск нужного ключа, в алгоритм полного перебора можно ввести распараллеливание, 
         то есть проводить нахождение ключей в разных потоках. Задачу распараллеливания можно решать по-разному, но 
         самое хорошее решение – это создание специального компьютерного вируса. Данный вирус будет использовать время, 
         когда компьютер «простаивает», для перебора по множеству ключей. В конце концов, один из компьютеров, на 
         который была установлена программа-взломщик, сможет отыскать нужный ключ.
         Недостаток этого метода состоит в том, что после нахождения каждого предположительно правильного ключа надо 
         проводить анализ дешифрованного текста на осмысленность. Вручную выполнять данный анализ практически 
         невозможно, поэтому этим занимаются ЭВМ.
         
   #### 1.5.2. Атака по ключам
   
         Как уже упоминалось, криптограф Огюст Керкгоффс сформулировал криптографический принцип, согласно которому 
         стойкость каждого криптоалгоритма напрямую связана с секретностью ключа шифра, поэтому криптографический шифр, 
         который претендует на высокую криптостойкость, должен не иметь слабых ключей. Однако, не все алгоритмы в 
         криптографии являются таковыми, поэтому данное требование Керкгоффса сводится к более простому: 
         «Криптографическая система должна иметь по возможности наименьшее количество слабых ключей». Если ключ 
         является слабым, то он не может обеспечить хороший уровень защиты криптографической системы.
         Стоит отметить, что главное уязвимое место криптографических алгоритмов – это ГПСЧ (генератор псевдослучайных 
         чисел). С помощью этого генератора, например, для симметричной криптосистемы, создается случайный двоичный 
         набор. Если используемый ключ имеет разрядность n, то ГПСЧ может сгенерировать один из 2^n вариантом. Для 
         асимметричных систем этот ключ обладает математическими свойствами, которые заданы в теле самого алгоритма.
         
   #### 1.5.3. Частотный анализ
   
         Этот вид анализа криптостойкости систем шифрования помогал криптогрофам и ученым на протяжении многих веков, а 
         основывается он на частоте появления отдельных символов или их сочетаний в кодируемом тексте. Для каждой буквы 
         составляется вероятность ее появления, при этом вероятности появления отдельных букв в сообщении будут 
         отличаться. Кроме отдельных символов, в дешифровании принимает участие и частотный анализ буквосочетаний.
         В отличие от аналитических методов, изучающих алгоритмы шифрования чисто математически, частотный анализ 
         добывает дополнительную информацию о ключе как раз с помощью статистических и лингвистических методов.
         Однако, после появления частотного анализа кодируемые сообщения начали составлять хитрее – теперь в шифртексте 
         символы распределялись равномерно, что намного усложнило задачу поиска нужного ключа.
         
   #### 1.5.4. Метод Полларда
   
         Допустим, что на некотором конечном множестве M определено случайное отображение f и ко всем элементам x, 
         принадлежащем множеству M, применили отображение. Далее все элементы x, y соединяются дугами, потому что 
         x=f(y), и получается волновой (функциональный) граф первого рода. При этом, все компоненты связности являются 
         деревьями, начинающимися из самого цикла. В итоге, длина цикла и высота дерева для случайного отображения f 
         равны O(sqrt(|M|)).
         Чтобы понять данный алгоритм, применим метод Полларда для нахождения двух аргументов, дающих одинаковое 
         значение хэш-функции, то есть коллизии. Отметим, что аргументы – это элементы множества M, стрелки от 
         элементов  под действием хэш-функции f отходят от входа в цикл. У алгоритма есть параметр – число v, 
         представляющее из себя доступную память. Весь алгоритм включает в себя следующие действия:
             • Входим в цикл, используя для i-ой точки траектории для входа x0 равенство xi=x2i=t;
             • Применяем последовательно отображение f к элементу t, получаем равенство f^m(t)=t, а затем измеряем 
             длину цикла m;
             • Разбиваем цикл на v, по возможности, одинаковых интервалов, запоминаем и упорядочиваем начальные точки 
             интервалов, а затем создаем базу данных;
             • Для стартовой вершины xi выполняем шаги до встречи с точкой из базы данных и отмечаем начальную, 
             конечные точки того интервала, на котором произошла встреча;
             • Стираем старую и создаем новую базу, разбиваем интервал, на котором произошла встреча, на v, по 
             возможности, одинаковых отрезков, запоминаем и упорядочиваем начальные точки интервалов;
             • Повторяем последние шаги, пока длина интервала не будет равна 1, потом вычисляем точку встречи в цикле, 
             а также пару вершин (коллизию).
         Сложность такого алгоритма равна O(sqrt(|M|)*logv(|M)).
         
   #### 1.5.5. Метод «встречи посередине»
   
         Несмотря на то, что данный способ криптоанализа требует столько же памяти, сколько и метод Полларда, к нему 
         можно применить распараллеливание. Метод «встречи посередине» активно использует «парадокс дней рождения», где 
         сказано, что в группе из 24-ех человек с вероятностью 0,5 у двух человек дни рождения окажутся в один день. 
         Другими словами, если всего у нас выбирается a*sqrt(b) предметов с возвращением из множества, размером b, то 
         вероятность того, что два из этих предметов совпадут, составляет  .
         Рассмотрим метод на следующем примере: пусть у нас известен открытый текст x и его криптограмма y (начальный и 
         зашифрованный текст). Тогда для нашего текста строится база данных, состоящая из случайного множества ключей 
         k’, и соответствующие ей криптограммы w=F(k’,x). Затем случайным образом подбираются ключи k’’ для расшифровки 
         текстов y, и получается результат расшифрования v=F(k’’,y), который в дальнейшем будет сравниваться с базой 
         данных. Если в результате сравнения получилось, что текст равен одной из криптограмм (w=v), то ключ k’=k’’ – 
         это нужный ключ k.
         Для этого метода объем базы данных будет составлять O(sqrt(|{k’}|), где |{k’}| - мощность множества ключей k’; 
         требуемая память же занимает O(sqrt(a)*loga) бит.